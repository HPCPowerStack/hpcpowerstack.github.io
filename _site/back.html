<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>The HPC PowerStack</title>
<meta name="generator" content="Jekyll v3.6.2" />
<meta property="og:title" content="The HPC PowerStack" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/back.html" />
<meta property="og:url" content="http://localhost:4000/back.html" />
<meta property="og:site_name" content="The HPC PowerStack" />
<script type="application/ld+json">
{"url":"http://localhost:4000/back.html","headline":"The HPC PowerStack","@type":"WebPage","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">The HPC PowerStack</h1>
	<h2 class="project-tagline">A Path to Standardization and/or Homogenization?</h2>
	<!-- 
	 <h2 class="project-tagline"></h2>
	-->

	<a href="http://powerstack.lrr.in.tum.de" class="btn">Home</a>
	<a href="http://powerstack.lrr.in.tum.de/raitenhaslach.html" class="btn">Raitenhaslach</a>
	<a href="http://powerstack.lrr.in.tum.de/proto.html" class="btn">Prototypes</a>
        <a href="http://powerstack.lrr.in.tum.de/org.html" class="btn">Members</a>
	<!-- 	
	<a href="http://powerstack.lrr.in.tum.de/agenda.html" class="btn">Agenda</a>
	<a href="http://powerstack.lrr.in.tum.de/travel.html" class="btn">Travel</a>
	-->
      
</section>

    <section class="main-content">
      <h2 id="background"><a href="#header-2"></a>Background</h2>

<p>The landscape of high-performance computing (HPC) is changing as we enter the exascale era. Power and energy management are key design points for the next generation of supercomputers. Efficiently utilizing procured power and optimizing performance of scientific applications under power and energy constraints is challenging due to several reasons, such as the dynamic phase behavior of applications, processor manufacturing variability, and increasing heterogeneity of node-level components. While several scattered research efforts to manage power and energy exist, a majority of these efforts are site-specific, require programmer effort, and often result in suboptimal application performance and system throughput. Additionally, these interfaces are not designed to cooperate or work together in an integrated manner, creating conflicts between various layers of a software stack. A holistic, generalizable and extensible approach to power management is still missing in the HPC community.</p>

<p>In this seminar, our goal is bring together experts from academia, research laboratories and industry in order to design a holistic and an extensible power management framework, which we refer to as the PowerStack. The PowerStack will explore hierarchical interfaces for power management at three specific levels: batch job schedulers, job-level runtime systems, node-level managers. Each level will provide options for adaptive management depending on requirements of the supercomputing site under consideration. Site-specific requirements such as cluster-level power bounds, user fairness, or job priorities will be translated as inputs to the job scheduler. The cluster-level job scheduler will choose power-aware scheduling plugins to ensure site-level compliance, with the primarily responsibility for allocation of nodes and job-level power constraints across multiple users and diverse workloads. Such allocations of physical nodes and job-level power bounds will serve as inputs to a fine-grained, job-level runtime system to manage specific application ranks, in-turn relying on vendor-agnostic node-level measurement and control mechanisms. Continuous monitoring and analysis of application behavior may be required for decision-making. The figure below presents an overview of the envisioned PowerStack, which takes a holistic approach to power management.</p>

<p><br /></p>

<p><img src="PowerStack_v2.png" alt="" /></p>

<p><br />
Design and development of the PowerStack in a scalable, conflict-free and low-overhead manner presents several challenges. Some of these challenges, which will be discussed and defined extensively in the proposed seminary, are listed below:</p>

<ul>
  <li>Holistically coordinate power optimizations across the whole system in a scalable manner</li>
  <li>Ensure safe operation within electrical operating parameters, must include protective layers to enable scenarios where system power caps are hard limits that must be enforced at all times</li>
  <li>Implementations must be open source with a flexible (not-sticky) software license to enable commercial as well as research uses</li>
  <li>Must be cross-platform to avoid locking users to hardware from a specific vendor</li>
  <li>Must be production-grade and easily deployable through standard package management interfaces</li>
  <li>Must be extensible (e.g. through plugins) to support diverse preferences at different HPC centers and facilitate rapid prototyping of new power, energy or performance optimization techniques</li>
  <li>Must be able to integrate components from multiple vendors and developers using a set of well-defined and possibly standardized interfaces</li>
  <li>Must support real-time monitoring and control in order to adapt to dynamic scenarios. These can be system-level (more or less power at the system level due to power supply or node failures), or application-level (critical path, CPU/memory boundedness, manufacturing variation in the allocation, load imbalance, etc.)</li>
</ul>


      <footer class="site-footer">
	<center>
	<p>
	<img src="/tum-s.png" alt="TUM" height=50>
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<img src="/llnl.png" alt="LLNL" height=50>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<img src="/tokyo.png" alt="U of Tokyo" height=50>
        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	<img src="/intel.jpg" alt="Intel" height=50>
	</p>
	<p>
	Impressum: <a href="https://www.tum.de/die-tum/kontakt-und-anfahrt/impressum/">TU Munich</a>, 
		   <a href="http://www.in.tum.de/impressum/">Department for Informatics</a>, 
	    	   <a href="http://www.lrr.in.tum.de/startseite/">Lehrstuhl I-10 (LRR)</a>, 
		   Contact: <a href="http://www.lrr.in.tum.de/mitarbeiter/martin-schulz/">Martin Schulz</a>
	<br>
	<a href="https://www.tum.de/datenschutz/">Datenschutz</a>
	</p>
	</center>
	</footer>
    </section>

    
  </body>
</html>
