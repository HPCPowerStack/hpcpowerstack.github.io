<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>HPC PowerStack | Website for the Raitenhaslach Seminar, June 20 to June 22, 2018, Germany.</title>
<meta name="generator" content="Jekyll v3.6.2" />
<meta property="og:title" content="HPC PowerStack" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Website for the Raitenhaslach Seminar, June 20 to June 22, 2018, Germany." />
<meta property="og:description" content="Website for the Raitenhaslach Seminar, June 20 to June 22, 2018, Germany." />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="HPC PowerStack" />
<script type="application/ld+json">
{"headline":"HPC PowerStack","description":"Website for the Raitenhaslach Seminar, June 20 to June 22, 2018, Germany.","name":"HPC PowerStack","@type":"WebSite","url":"http://localhost:4000/","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">The HPC PowerStack - An Attempt at Standardization and/or Homogenization</h1>
      <h2 class="project-tagline">June 20 to June 22, 2018, Akademiezentrum Raitenhasslach, Germany.</h2>
      
      
	<a href="https://hpcpowerstack.lrr.in.tum.de" class="btn">Home</a>
        <a href="https://hpcpowerstack.lrr.in.tum.de/back.html" class="btn">Background</a>
	<a href="https://hpcpowerstack.lrr.in.tum.de/org.html" class="btn">Organizers</a>
	<a href="https://hpcpowerstack.lrr.in.tum.de/agenda.html" class="btn">Agenda</a>
	<a href="https://hpcpowerstack.lrr.in.tum.de/travel.html" class="btn">Travel</a>
      
    </section>

    <section class="main-content">
      <p>The landscape of high-performance computing (HPC) is changing as we enter the exascale era. Power and energy management are key design points for the next generation of supercomputers. Efficiently utilizing procured power and optimizing performance of scientific applications under power and energy constraints is challenging due to several reasons, such as the dynamic phase behavior of applications, processor manufacturing variability, and increasing heterogeneity of node-level components. While several scattered research efforts to manage power and energy exist, a majority of these efforts are site-specific, require programmer effort, and often result in suboptimal application performance and system throughput. Additionally, these interfaces are not designed to cooperate or work together in an integrated manner, creating conflicts between various layers of a software stack. A holistic, generalizable and extensible approach to power management is still missing in the HPC community.</p>

<p>In this seminar, our goal is bring together experts from academia, research laboratories and industry in order to design a holistic and an extensible power management framework, which we refer to as the PowerStack. The PowerStack will explore hierarchical interfaces for power management at three specific levels: batch job schedulers, job-level runtime systems, node-level managers. Each level will provide options for adaptive management depending on requirements of the supercomputing site under consideration. Site-specific requirements such as cluster-level power bounds, user fairness, or job priorities will be translated as inputs to the job scheduler. The cluster-level job scheduler will choose power-aware scheduling plugins to ensure site-level compliance, with the primarily responsibility for allocation of nodes and job-level power constraints across multiple users and diverse workloads. Such allocations of physical nodes and job-level power bounds will serve as inputs to a fine-grained, job-level runtime system to manage specific application ranks, in-turn relying on vendor-agnostic node-level measurement and control mechanisms. Continuous monitoring and analysis of application behavior may be required for decision-making. The figure below presents an overview of the envisioned PowerStack, which takes a holistic approach to power management.</p>

<p><br /></p>

<p><img src="PowerStack_v2.png" alt="" /></p>

<p><br />
Design and development of the PowerStack in a scalable, conflict-free and low-overhead manner presents several challenges. Some of these challenges, which will be discussed and defined extensively in the proposed seminary, are listed below:</p>

<ul>
<li> Holistically coordinate power optimizations across the
whole system in a scalable manner
<li>Ensure safe operation within electrical operating
parameters, must include protective layers to enable
scenarios where system power caps are hard limits that
must be enforced at all times 
<li>Implementations must be open source with a flexible
(not-sticky) software license to enable commercial as
well as research uses
<li>Must be cross-platform to avoid locking users to
hardware from a specific vendor
<li>Must be production-grade and easily deployable through
standard package management interfaces  
<li>Must be extensible (e.g. through plugins) to support
diverse preferences at different HPC centers and
facilitate rapid prototyping of new power, energy or
performance optimization techniques
<li>Must be able to integrate components from multiple
vendors and developers using a set of well-defined and
possibly standardized interfaces</li>
<li>Must support real-time monitoring and control in order
to adapt to dynamic scenarios. These can be
system-level (more or less power at the system level
due to power supply or node failures), or
application-level (critical path, CPU/memory
boundedness, manufacturing variation in the allocation,
load imbalance, etc.)</li> 
</ul>




<!--
<ul>
  <li>Measurement and control mechanisms may use different underlying techniques (power capping versus frequency scaling) as well as different granularities (ranging from one millisecond to several hundred milliseconds) depending on the underlying node-level component and the vendor. How do we integrate data collected across different granularities? How do we decide on the granularities and frequencies of measurement and control?</li>
  <li>How do we compress, store and query measured application profile data?</li>
  <li>How do we expose a common vendor-neutral API to the job-level runtime system given the various underlying vendor-specific mechanisms?</li>
  <li>How do we balance user priorities, fairness and charging requirements when maximizing for better utilization and throughput in job schedulers?</li>
  <li>How do we ensure safe operation and trust among the management levels? How do we resolve conflicts while ensuring safe operation?</li>
  <li>How do we define the communication protocol across these levels?</li>
  <li>How do we address the security aspects of such a power stack? What levels of measurement and control should be exposed to the application developer and the users?</li>
</ul>
-->

      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  </body>
</html>
